# AI Multi-Agent Starter Kit - Environment Variables

# Environment
ENVIRONMENT=development

# Execution Mode
# DRY_RUN mode: All external API calls are mocked (zero cost)
# Set to 'false' only when you have sufficient API credits and want real execution
DRY_RUN=true

# Runner Configuration
# RUNNER_ENABLED: Set to 'false' to disable background task execution
# Only enable when you have sufficient credits and want 24/7 operation
RUNNER_ENABLED=false

# Runner Job Intervals (in seconds)
RUNNER_LOOP_INTERVAL=60
RUNNER_HEARTBEAT_SECONDS=30
RUNNER_CLEANUP_SECONDS=600

# Runner Concurrency and Error Handling
RUNNER_MAX_CONCURRENCY=4
RUNNER_MAX_ERRORS=5
BACKOFF_BASE_SECONDS=2
RUNNER_MAX_BACKOFF=300

# Runner Watchdog
RUNNER_WATCHDOG_ENABLED=true
RUNNER_WATCHDOG_TIMEOUT=600

# Runner Rate Limiting
RUNNER_MAX_JOBS_PER_MINUTE=10
RUNNER_MAX_JOBS_PER_HOUR=100

# Runner Storage and Logging
RUNNER_LOG_DIR=storage/runs
RUNNER_LOG_ROTATION_DAYS=30
RUNNER_SHUTDOWN_TIMEOUT=30

# Notification Configuration
# Channels: comma-separated list (e.g., "email,slack")
# Leave empty to disable notifications
NOTIFY_CHANNELS=

# Email Notification (SMTP)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password
SMTP_FROM=your-email@gmail.com
SMTP_TO=recipient@example.com

# Slack Notification
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Notification Storage (DRY_RUN mode)
NOTIFICATIONS_FILE=storage/notifications.jsonl

# API Keys
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
GEMINI_API_KEY=your-gemini-api-key-here
PERPLEXITY_API_KEY=your-perplexity-key

# LLM Configuration
# OpenAI is disabled by default (set to 'true' to enable)
OPENAI_ENABLED=false

# LLM Provider Priority (comma-separated)
# Default: anthropic,gemini,perplexity
LLM_PRIORITY=anthropic,gemini,perplexity

# Perplexity Search-Only Mode (prevents usage for non-search tasks)
# Default: true (recommended to avoid unnecessary costs)
PERPLEXITY_SEARCH_ONLY=true

# Budget and Cost Controls
# Maximum daily cost in USD (0.0 = zero-cost mode with mocked API calls)
LLM_DAILY_MAX_COST_USD=0.0

# Maximum Perplexity requests per day (0 = disabled in DRY_RUN mode)
PERPLEXITY_MAX_REQUESTS_PER_DAY=0

# Timeout and Retry Settings
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3

# Model Selection (optional - defaults are set in llm_router.py)
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=4096

GEMINI_MODEL=gemini-1.5-pro
GEMINI_MAX_TOKENS=8192

PERPLEXITY_MODEL=llama-3.1-sonar-large-128k-online
PERPLEXITY_MAX_TOKENS=4096

OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4096

# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ai_agents

# Redis
REDIS_URL=redis://localhost:6379

# API Server
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO

# Applications Config
# Care Scheduler
CARE_SCHEDULER_ENABLED=true

# SNS Auto
SNS_AUTO_ENABLED=true
TWITTER_API_KEY=
TWITTER_API_SECRET=
FACEBOOK_ACCESS_TOKEN=
INSTAGRAM_ACCESS_TOKEN=
LINKEDIN_ACCESS_TOKEN=

# HR Matching
HR_MATCHING_ENABLED=true

# Security
SECRET_KEY=your-secret-key-here
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
